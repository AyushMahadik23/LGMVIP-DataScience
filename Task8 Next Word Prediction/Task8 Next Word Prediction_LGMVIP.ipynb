{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: Ayush Mahadik\n",
    "#Task: Next Word Prediction\n",
    "#Batch: LGMVIP - DataScience (May)\n",
    "#Details: Below are some queries performed on given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-HvypT2NEENp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm0syQY_9Qdt"
   },
   "source": [
    "Now load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vVqE2ZXE902",
    "outputId": "9b4babd5-c9ee-43d1-cedf-8b008c8a59d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581888\n"
     ]
    }
   ],
   "source": [
    "text = open('1661-0.txt').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Wd1PQpG9Ze7"
   },
   "source": [
    "Now, we want to split the entire dataset into each word in order without the presence of special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SSsvgtTvFRrD"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zd2LXoU9fdq"
   },
   "source": [
    "Next, for the feature engineering part, we need to have the unique sorted words list. We also need a dictionary with each word form the unique_words list as key and its corresponding position as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BUcAoWZZFWMy"
   },
   "outputs": [],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLYtcLaP9ooD"
   },
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQWzoczJFbMS",
    "outputId": "37334a3f-e3f5-4bb9-d664-941c7414cc41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 's', 'the', 'adventures']\n",
      "of\n"
     ]
    }
   ],
   "source": [
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words) - WORD_LENGTH):\n",
    "    prev_words.append(words[i:i + WORD_LENGTH])\n",
    "    next_words.append(words[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGx12wc39wKx"
   },
   "source": [
    "Here, we create two numpy array X(for storing the features) and Y(for storing the corresponding label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "txyV5RUZFilA"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RMUmMEPYFl05"
   },
   "outputs": [],
   "source": [
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvgR0BUkGUPg",
    "outputId": "c3d74842-b8c8-4248-86aa-28218fc2e2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uxsfQ4B93Hu"
   },
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4JJMCKpjkJQE"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V329LBq09-fN"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3G_oqcZRkQgs",
    "outputId": "b8773e86-8ec2-41f8-c63c-40a2e42d434a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "811/811 [==============================] - 290s 353ms/step - loss: 6.0101 - accuracy: 0.1073 - val_loss: 7.0723 - val_accuracy: 0.1033\n",
      "Epoch 2/20\n",
      "811/811 [==============================] - 285s 352ms/step - loss: 5.7724 - accuracy: 0.1482 - val_loss: 7.7905 - val_accuracy: 0.1023\n",
      "Epoch 3/20\n",
      "811/811 [==============================] - 287s 354ms/step - loss: 5.7672 - accuracy: 0.1746 - val_loss: 7.9921 - val_accuracy: 0.1100\n",
      "Epoch 4/20\n",
      "811/811 [==============================] - 285s 352ms/step - loss: 5.4483 - accuracy: 0.2089 - val_loss: 8.2435 - val_accuracy: 0.1077\n",
      "Epoch 5/20\n",
      "811/811 [==============================] - 283s 349ms/step - loss: 5.1461 - accuracy: 0.2487 - val_loss: 8.2791 - val_accuracy: 0.0932\n",
      "Epoch 6/20\n",
      "811/811 [==============================] - 281s 346ms/step - loss: 4.8995 - accuracy: 0.2872 - val_loss: 8.5497 - val_accuracy: 0.0921\n",
      "Epoch 7/20\n",
      "811/811 [==============================] - 283s 349ms/step - loss: 4.6633 - accuracy: 0.3270 - val_loss: 8.7364 - val_accuracy: 0.0820\n",
      "Epoch 8/20\n",
      "811/811 [==============================] - 280s 345ms/step - loss: 4.4487 - accuracy: 0.3660 - val_loss: 8.9473 - val_accuracy: 0.0811\n",
      "Epoch 9/20\n",
      "811/811 [==============================] - 281s 346ms/step - loss: 4.2640 - accuracy: 0.4001 - val_loss: 8.9686 - val_accuracy: 0.0817\n",
      "Epoch 10/20\n",
      "811/811 [==============================] - 283s 349ms/step - loss: 4.1028 - accuracy: 0.4327 - val_loss: 9.0779 - val_accuracy: 0.0796\n",
      "Epoch 11/20\n",
      "811/811 [==============================] - 280s 345ms/step - loss: 3.9755 - accuracy: 0.4583 - val_loss: 9.2592 - val_accuracy: 0.0738\n",
      "Epoch 12/20\n",
      "811/811 [==============================] - 279s 345ms/step - loss: 3.8584 - accuracy: 0.4836 - val_loss: 9.6390 - val_accuracy: 0.0721\n",
      "Epoch 13/20\n",
      "811/811 [==============================] - 279s 344ms/step - loss: 3.7411 - accuracy: 0.5065 - val_loss: 9.5739 - val_accuracy: 0.0674\n",
      "Epoch 14/20\n",
      "811/811 [==============================] - 280s 346ms/step - loss: 3.6397 - accuracy: 0.5257 - val_loss: 9.8334 - val_accuracy: 0.0709\n",
      "Epoch 15/20\n",
      "811/811 [==============================] - 275s 338ms/step - loss: 3.5659 - accuracy: 0.5406 - val_loss: 9.9629 - val_accuracy: 0.0712\n",
      "Epoch 16/20\n",
      "811/811 [==============================] - 280s 346ms/step - loss: 3.5275 - accuracy: 0.5520 - val_loss: 9.6935 - val_accuracy: 0.0657\n",
      "Epoch 17/20\n",
      "811/811 [==============================] - 275s 339ms/step - loss: 3.5098 - accuracy: 0.5619 - val_loss: 9.7012 - val_accuracy: 0.0663\n",
      "Epoch 18/20\n",
      "811/811 [==============================] - 279s 344ms/step - loss: 3.4641 - accuracy: 0.5735 - val_loss: 9.6079 - val_accuracy: 0.0648\n",
      "Epoch 19/20\n",
      "811/811 [==============================] - 278s 343ms/step - loss: 3.4099 - accuracy: 0.5838 - val_loss: 9.7905 - val_accuracy: 0.0676\n",
      "Epoch 20/20\n",
      "811/811 [==============================] - 278s 343ms/step - loss: 3.3639 - accuracy: 0.5924 - val_loss: 9.6041 - val_accuracy: 0.0672\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lqMWZVH-Hpz"
   },
   "source": [
    "After successful training, we will save the trained model and just load it back as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "n3jZXM23kQjk"
   },
   "outputs": [],
   "source": [
    "model.save('keras_next_word_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "\n",
    "model = load_model('keras_next_word_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuZDFmxp-N1s"
   },
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vB7w0nS9kr0m",
    "outputId": "e9573293-0656-41a8-eb68-e9d26140e315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "is\n",
      "not\n",
      "a\n",
      "lack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"It is not a lack\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpXnGnlm-XOB"
   },
   "source": [
    "To choose the best possible n words after the prediction from the model is done by sample function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kkChqBGNkxZe"
   },
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIteGNik-bPw"
   },
   "source": [
    "Finally, for prediction, we use the function predict_completions which use the model to predict and return the list of n predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CcAtRpC8k1J8"
   },
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    if text == \"\":\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaviFg63-fa5"
   },
   "source": [
    "Now let’s see how it predicts, we use tokenizer.tokenize fo removing the punctuations and also we choose 5 first words because our predicts base on 5 previous words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKXfnf34k1Tc",
    "outputId": "e04cd64b-104d-4474-f549-cbea43594006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct sentence:  Your life will never be there in the same situation again\n",
      "Sequence:  your life will never be\n",
      "your\n",
      "life\n",
      "will\n",
      "never\n",
      "be\n",
      "next possible words:  ['and', 'at', 'that', 'very', 'too']\n"
     ]
    }
   ],
   "source": [
    "q =  \"Your life will never be there in the same situation again\"\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGuGem9V-jl0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
